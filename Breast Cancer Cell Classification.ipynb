{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_PROJECT",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-Nagaraju/Analysis-of-ML-algorithms-for-accurate-Breast-Cancer-Classification/blob/master/Breast%20Cancer%20Cell%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25XTVBStPjrK"
      },
      "source": [
        "import smtplib\n",
        "\n",
        "server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
        "server.login(\"rakenju@gmail.com\", \"2180user\")\n",
        "server.sendmail(\n",
        "  \"rakenju@gmail.com\", \n",
        "  \"rakenju@gmail.com\", \n",
        "  \"this message is from python\")\n",
        "server.quit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5AhSJFAa0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "538aea20-1165-4e9f-b834-47959443f57c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [98,97,96,95,94,93,98,99]\n",
        "num_bins = 100\n",
        "n, bins, patches = plt.hist(x, num_bins, facecolor='blue', alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6t7zRLugpSl"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62bdf8LcbIT9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "93aee27d-12a0-4847-c104-7831c834dbfa"
      },
      "source": [
        "!pip3 install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPw2KCs-2B1L"
      },
      "source": [
        "# coding=utf-8\n",
        "#%matplotlib inline\n",
        "#Breast Cancer Cell classification\n",
        "#Author: Rakesh Nagaraju (014279304) \n",
        "#importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from scipy import interp\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from inspect import signature\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#Main class\n",
        "class Machine_Learning_Algorithm():\n",
        " def __init__(self):\n",
        "   self.colors = ['brown', 'burlywood', 'cadetblue', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue',  'crimson',\n",
        "    'cyan', 'cornsilk', 'darkcyan', 'darkgoldenrod', 'darkgray', 'darkgreen', 'darkgrey', 'darkkhaki','darkblue', 'darkmagenta', 'darkolivegreen',\n",
        "    'darkorange', 'goldenrod', 'gray', 'yellow','burlywood', 'cadetblue', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue',  'crimson',\n",
        "    'cyan', 'cornsilk', 'darkcyan']\n",
        "   self.reversed_mean_precision = 0.0\n",
        "   self.mean_fpr = np.linspace(0, 1, 100)\n",
        "   self.mean_recall = np.linspace(0, 1, 100)\n",
        "   self.Scores = []\n",
        "   self.Pre_recall_list = []\n",
        "   self.tprs=[]\n",
        "   self.Tprs=[]\n",
        "   self.aucs=[]\n",
        "   self.Mean_auc = []\n",
        "   self.FP_TPR = []\n",
        "   self.aucc = []\n",
        "\n",
        "#importing our cancer dataset\n",
        " def import_data(self,file_name):\n",
        "  self.dataset = pd.read_csv(file_name)\n",
        "  self.X = self.dataset.iloc[:, 2:32].values\n",
        "  self.Y = self.dataset.iloc[:, 1].values\n",
        "\n",
        "#Remove Headers, Store True Classification Scores of each record, Scale every values columnwise. \n",
        " def classify_data(self): \n",
        "  self.dataset.head()       \n",
        "  #print(\"Cancer data set dimensions : {}\".format(dataset.shape))\n",
        "##We can find any missing or null data points of the data set (if there is any)\n",
        "## using the following pandas function.\n",
        "  self.z = self.dataset.isnull().sum()\n",
        "  self.z1 = self.dataset.isna().sum()\n",
        "##Encoding categorical data values\n",
        "#Malware is 1 and Benign is 0\n",
        "  self.labelencoder_Y = LabelEncoder()\n",
        "  self.Y = self.labelencoder_Y.fit_transform(self.Y)\n",
        "\n",
        "#Function to predict the trained model\n",
        " def predict_trained_model(self,name,X_test,Y_test):\n",
        "  self.X_test = X_test\n",
        "  self.Y_test = Y_test\n",
        "  self.name = name \n",
        "  self.Y_pred = self.classifier.predict(X_test) \n",
        "  self.Scores.append((self.d).score(X_test,Y_test))\n",
        "  self.Y_pred = [ 1 if i>=0.5 else 0 for i in self.Y_pred]\n",
        "  self.Confusion_Matrix() \n",
        "  self.roc_cal()\n",
        "  self.PR_cal()\n",
        "\n",
        "#Generate Confusion Matrix\n",
        " def Confusion_Matrix(self):\n",
        "  self.confusion_matrix = confusion_matrix(self.Y_test, self.Y_pred)  \n",
        "  self.classify_report = classification_report(self.Y_test, self.Y_pred)  \n",
        "  print(\"Confusion Matrix on\",self.name,\"for fold\",self.i,\":\\n\" +format(self.confusion_matrix)) \n",
        "  print(\"Classification Report on\",self.name,\"for fold\",self.i,\":\\n\" +format(classification_report(self.Y_test, self.Y_pred)))\n",
        "  print(\"Accuracy of\",self.name,\"for fold\",self.i,\":\\n\" +format(balanced_accuracy_score(self.Y_test, self.Y_pred)))\n",
        "  self.average_precision = average_precision_score(self.Y_test, self.Y_pred)\n",
        "\n",
        "   # Compute ROC curve and area the curve\n",
        " def roc_cal(self):\n",
        "    self.result1 = roc_auc_score(self.Y_test, self.Y_pred)   \n",
        "    self.fpr, self.tpr, self.thresholds = roc_curve(self.Y_test, self.Y_pred)\n",
        "    self.tprs.append(interp(self.mean_fpr, self.fpr, self.tpr))\n",
        "    self.tprs[-1][0] = 0.0\n",
        "    self.roc_auc = auc(self.fpr, self.tpr)\n",
        "    self.aucs.append(self.roc_auc)\n",
        "    self.FP_TPR.append(self.fpr)\n",
        "    self.FP_TPR.append(self.tpr)\n",
        "    self.FP_TPR.append(self.i)\n",
        "    self.FP_TPR.append(self.roc_auc)\n",
        "\n",
        " def roc_plot(self):\n",
        "   plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "   for j in range(0,len(self.FP_TPR),4):\n",
        "    plt.plot(self.FP_TPR[j], self.FP_TPR[j+1], lw=1,color=self.colors[j], alpha=0.4,\n",
        "             label='ROC fold for %d (AUC = %0.2f)' % (self.FP_TPR[j+2], self.FP_TPR[j+3]))\n",
        "   plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
        "   self.mean_tpr = np.mean(self.tprs, axis=0)\n",
        "   self.mean_tpr[-1] = 1.0\n",
        "   self.mean_auc = auc(self.mean_fpr, self.mean_tpr)\n",
        "   self.std_auc = np.std(self.aucs) \n",
        "   plt.plot(self.mean_fpr, self.mean_tpr, color='b',\n",
        "          label=r'Mean ROC for (AUC = %0.2f)' % (self.mean_auc),lw=2, alpha=.5)\n",
        "                 # label=r'Mean ROC for (AUC = %0.2f $\\pm$ %0.2f)' % (self.mean_auc, self.std_auc),lw=2, alpha=.5)  \n",
        "   self.std_tpr = np.std(self.tprs, axis=0)\n",
        "   plt.xlim([0.0, 1.0])\n",
        "   plt.ylim([0.0, 1.0])\n",
        "   plt.xlabel('FPR (False Positive Rate)')\n",
        "   plt.ylabel('TPR (True Positive Rate)')\n",
        "   plt.title('ROC for '+str(self.name))\n",
        "   plt.legend(loc=\"lower right\")\n",
        "   plt.show()\n",
        "#Remove data when processing is done!!!\n",
        " def recycle(self):\n",
        "   self.Scores.clear()\n",
        "   self.Pre_recall_list.clear()\n",
        "   self.tprs.clear()\n",
        "   self.Tprs.clear()\n",
        "   self.aucs.clear()\n",
        "   self.Mean_auc.clear()\n",
        "   self.FP_TPR.clear()\n",
        "   self.aucc.clear()\n",
        "\n",
        "# Compute PR curve and area the curve\n",
        " def PR_cal(self):\n",
        "  self.precision, self.recall,_ = precision_recall_curve(self.Y_test, self.Y_pred)\n",
        "  self.reversed_recall = np.fliplr([self.recall])[0]\n",
        "  self.reversed_precision = np.fliplr([self.precision])[0]\n",
        "  self.reversed_mean_precision += interp(self.mean_recall, self.reversed_recall, self.reversed_precision)\n",
        "  self.reversed_mean_precision[0] = 0.0\n",
        "  self.Mean_auc.append(metrics.auc(self.recall, self.precision))\n",
        "  self.f1_score = f1_score(self.Y_test, self.Y_pred)\n",
        "  self.PR_auc = auc(self.recall, self.precision)\n",
        "  self.Tprs.append(interp(self.mean_recall, self.recall, self.precision))\n",
        "  self.Tprs[-1][0] = 1.0\n",
        "  self.Pre_recall_list.append(self.precision)\n",
        "  self.Pre_recall_list.append(self.recall)\n",
        "  self.Pre_recall_list.append(self.i)\n",
        "  self.Pre_recall_list.append(self.f1_score)\n",
        "  self.Pre_recall_list.append(self.PR_auc)\n",
        " \n",
        " def plot_PR_curve(self):\n",
        "  plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "  self.reversed_mean_precision /= split\n",
        "  self.reversed_mean_precision[0] = 1\n",
        "  self.mean_auc_pr = auc(self.mean_recall, self.reversed_mean_precision)\n",
        "  c = 0\n",
        "  for j in range(0,len(self.Pre_recall_list),5):\n",
        "   plt.plot(self.Pre_recall_list[j], self.Pre_recall_list[j+1],lw=2,color=self.colors[c], \n",
        "   label='PR curve for fold %d (AUC = %0.2f) '%(self.Pre_recall_list[j+2],self.Pre_recall_list[j+4]),alpha=.3)\n",
        "   c += 1 \n",
        "  plt.plot(self.mean_recall,  self.reversed_mean_precision, 'k--',\n",
        "         label='Mean precision (AUC mean = %0.2f)' % self.mean_auc_pr,color = 'b',lw=2)\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.0])\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precison')\n",
        "  plt.title(' PR curve for '+str(self.name))\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "  self.recycle()\n",
        "\n",
        "#Using SVC method of svm class to use Support Vector Machine Algorithm\n",
        " def SVC_algo_linear(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing SVC with Linear Kernel...\")\n",
        "  self.classifier = SVC(kernel = 'linear', random_state = 0,C = 3, probability=True)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('SVC-linear',X_test,Y_test)\n",
        "\n",
        "#Using SVC method of svm class to use Kernel SVM Algorithm\n",
        " def SVC_algo_rbf(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing SVC with RBF Kernel...\")\n",
        "  self.classifier = SVC(kernel = 'rbf', random_state = 0,C = 3, probability=True)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('SVC-rbf',X_test,Y_test)\n",
        "\n",
        "#Using SVC method of svm class to use Kernel SVM Algorithm\n",
        " def SVC_algo_poly(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing SVC with Polynomial Kernel...\")\n",
        "  self.classifier = SVC(kernel = 'poly', random_state = 0,C = 3, probability=True)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('SVC-polynomial',X_test,Y_test)\n",
        "\n",
        "#Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
        " def Knn_algo(self,j,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing Knn Algorithm...\")\n",
        "  self.classifier = KNeighborsClassifier(n_neighbors = j, metric = 'minkowski', p = 2)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('Knn',X_test,Y_test)\n",
        "\n",
        "#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n",
        " def random_forest(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing Random Forest...\")\n",
        "  self.classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('Random Forest',X_test,Y_test)\n",
        "\n",
        "#Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n",
        " def gaussian_algo(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing Gaussian Algorithm...\")\n",
        "  self.classifier = GaussianNB()\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('Gaussian Algorithm',X_test,Y_test)\n",
        "\n",
        "#Using Logistic Regression Algorithm to the Training Set\n",
        " def logistic_regression(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing Logistic Regression...\")\n",
        "  self.classifier = LogisticRegression(penalty = 'l2',solver='lbfgs',random_state = 0,max_iter = 1000)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('Logistic Regression',X_test,Y_test)\n",
        "\n",
        "#Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n",
        " def decision_tree(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  print(\"Performing Decision Tree...\")\n",
        "  self.classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "  self.d = self.classifier.fit(X_train, Y_train)\n",
        "  self.predict_trained_model('Decision Tree',X_test,Y_test)\n",
        "\n",
        "#A Multilayer Perceptron with 2 hidden layers\n",
        " def neural_net(self,i,X_train,Y_train,X_test,Y_test):\n",
        "  self.i = i\n",
        "  self.name = 'Neural Network'\n",
        "  print(\"Training Neural Network...\")\n",
        "  self.classifier = Sequential()  \n",
        "  self.classifier.add(Dense(units = 5, activation = 'relu', input_dim=30))\n",
        "  #self.classifier.add(Dense(units = 7, activation = 'relu'))\n",
        "  self.classifier.add(Dense(units = 3, activation = 'relu'))\n",
        "  self.classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "  self.sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  self.classifier.compile(optimizer = self.sgd, loss = 'mean_squared_error', metrics=['accuracy'])\n",
        "  self.classifier.fit(X_train, Y_train, batch_size = 10, epochs = 1000)\n",
        "  self.Y_pred = self.classifier.predict(X_test) \n",
        "  self.Y_pred = [ 1 if i>=0.5 else 0 for i in self.Y_pred]\n",
        "  self.confusion_matrix = confusion_matrix(Y_test, self.Y_pred)  \n",
        "  self.classify_report = classification_report(Y_test, self.Y_pred)  \n",
        "  print(\"Confusion Matrix on\",self.name,\"for fold\",self.i,\":\\n\" +format(self.confusion_matrix)) \n",
        "  print(\"Classification Report on\",self.name,\"for fold\",self.i,\":\\n\" +format(classification_report(Y_test, self.Y_pred)))\n",
        "  print(\"Accuracy of\",self.name,\"for fold\",self.i,\":\\n\" +format(balanced_accuracy_score(Y_test, self.Y_pred)))\n",
        "  tmp = balanced_accuracy_score(Y_test, self.Y_pred)\n",
        "  self.aucc.append(tmp)\n",
        "  self.result1 = roc_auc_score(Y_test, self.Y_pred)   \n",
        "  self.fpr, self.tpr, self.thresholds = roc_curve(Y_test, self.Y_pred)\n",
        "  self.tprs.append(interp(self.mean_fpr, self.fpr, self.tpr))\n",
        "  self.tprs[-1][0] = 0.0\n",
        "  self.roc_auc = auc(self.fpr, self.tpr)\n",
        "  self.aucs.append(self.roc_auc)\n",
        "  self.FP_TPR.append(self.fpr)\n",
        "  self.FP_TPR.append(self.tpr)\n",
        "  self.FP_TPR.append(self.i)\n",
        "  self.FP_TPR.append(self.roc_auc)\n",
        "  self.precision, self.recall,_ = precision_recall_curve(Y_test, self.Y_pred)\n",
        "  self.reversed_recall = np.fliplr([self.recall])[0]\n",
        "  self.reversed_precision = np.fliplr([self.precision])[0]\n",
        "  self.reversed_mean_precision += interp(self.mean_recall, self.reversed_recall, self.reversed_precision)\n",
        "  self.reversed_mean_precision[0] = 0.0\n",
        "  self.Mean_auc.append(metrics.auc(self.recall, self.precision))\n",
        "  self.f1_score  = f1_score(Y_test, self.Y_pred)\n",
        "  self.PR_auc = auc(self.recall, self.precision)\n",
        "  self.Tprs.append(interp(self.mean_recall, self.recall, self.precision))\n",
        "  self.Tprs[-1][0] = 1.0\n",
        "  self.Pre_recall_list.append(self.precision)\n",
        "  self.Pre_recall_list.append(self.recall)\n",
        "  self.Pre_recall_list.append(self.i)\n",
        "  self.Pre_recall_list.append(self.f1_score)\n",
        "  self.Pre_recall_list.append(self.PR_auc)\n",
        "\n",
        "#main function\n",
        "def main_call(num):\n",
        " impl = Machine_Learning_Algorithm()\n",
        " impl.import_data(\"data.csv\")\n",
        " impl.classify_data()\n",
        " kf = KFold(n_splits=split) # Defining the split  \n",
        " kf.get_n_splits(impl.X) # returns the number of splitting iterations in the cross-validator\n",
        " KFold(n_splits=split, random_state=None, shuffle=False)\n",
        " i = 0\n",
        " for train_index, test_index in kf.split(impl.X):\n",
        "   X_train, X_test = impl.X[train_index], impl.X[test_index]\n",
        "   Y_train, Y_test = impl.Y[train_index], impl.Y[test_index]\n",
        "#Scaling\n",
        "   stand_scale = StandardScaler()\n",
        "   X_train = stand_scale.fit_transform(X_train)\n",
        "   X_test = stand_scale.transform(X_test)\n",
        "   if (num == 1): impl.logistic_regression(i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 2): impl.Knn_algo(k,i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 310): impl.SVC_algo_linear(i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 311): impl.SVC_algo_rbf(i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 312): impl.SVC_algo_poly(i,X_train,Y_train,X_test,Y_test)  \n",
        "   elif (num == 4): impl.gaussian_algo(i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 5): impl.decision_tree(i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 6): impl.random_forest(i,X_train,Y_train,X_test,Y_test)\n",
        "   elif (num == 7): impl.neural_net(i,X_train,Y_train,X_test,Y_test)\n",
        "   else: break\n",
        "   i += 1\n",
        " if (num != 7):\n",
        "  print(\"Average mean accuracy of all for\",impl.name,\"is = \",np.mean(impl.Scores))\n",
        " else:\n",
        "   print(\"Average mean accuracy of all for Neural Network is:\",(sum(impl.aucc)/len(impl.aucc))*100)\n",
        " impl.roc_plot()\n",
        " impl.plot_PR_curve()\n",
        " return()\n",
        "def analyze_data():\n",
        "  # read the file\n",
        "  data = pd.read_csv('data.csv')\n",
        "  # Checking the data set\n",
        "  data.head()\n",
        "  # Cleaning and modifying the data\n",
        "  data = data.drop('id',axis=1)\n",
        "  data = data.drop('Unnamed: 32',axis=1)\n",
        "  # Mapping Benign to 0 and Malignant to 1 \n",
        "  data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
        "  #Check the data stats\n",
        "  data.describe()\n",
        "  # Scaling the dataset\n",
        "  datas = pd.DataFrame(preprocessing.scale(data.iloc[:,1:32]))\n",
        "  datas.columns = list(data.iloc[:,1:32].columns)\n",
        "  datas['diagnosis'] = data['diagnosis']\n",
        "  datas.head() \n",
        "\n",
        " #draw a heatmap between mean features and diagnosis\n",
        "  features_mean = ['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean', 'compactness_mean', 'concavity_mean','concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
        "  plt.figure(figsize=(14,14))\n",
        "  heat = sns.heatmap(datas[features_mean].corr(),square=True, vmax=1, annot=True,fmt='f')\n",
        "\n",
        "   # Splitting the dataset into malignant and benign.\n",
        "  dataMalignant=datas[datas['diagnosis'] ==1]\n",
        "  dataBenign=datas[datas['diagnosis'] ==0]\n",
        "\n",
        "  #Plotting these features as a histogram\n",
        "  fig, axes = plt.subplots(nrows=10, ncols=1, figsize=(15,60))\n",
        "  for idx,ax in enumerate(axes):\n",
        "     ax.figure\n",
        "     binwidth= (max(datas[features_mean[idx]]) - min(datas[features_mean[idx]]))/250\n",
        "     ax.hist([dataMalignant[features_mean[idx]],dataBenign[features_mean[idx]]], bins=np.arange(min(datas[features_mean[idx]]), max(datas[features_mean[idx]]) + binwidth, binwidth) , density=True, alpha=0.5,stacked=True, label=['M','B'],color=['r','g'])\n",
        "     ax.legend(loc='upper right')\n",
        "     ax.set_title(features_mean[idx])\n",
        "  plt.show()\n",
        "#Menu displayed at the start.\n",
        "print(\"Welcome!!!\")\n",
        "print(\"Loaded Wisconsin Breast Cancer Dataset\")\n",
        "print(\"Enter the number given below to run preferred Algorithm:\")\n",
        "print(\"0.Analyze data\\n1.Logistic Regression\\n2.Knn\\n3.SVC\\n4.Gaussian Algorithm\\n5.Decision Tree\\n6.Random Forest\\n7.Neural Network\\n8.ALL the above\")\n",
        "val = int(input(\"Input Algorithm number:\"))\n",
        "if val ==0 :\n",
        "  analyze_data()\n",
        "else:\n",
        " try:\n",
        "  splt = int(input(\"Enter number of splits(default=5):\"))\n",
        "  if splt > 29:\n",
        "   print(\"Entered value is greater...assuming default folds(5)\")\n",
        "   split = 5\n",
        "  else:split = splt\n",
        " except:\n",
        "  print(\"Invalid value....assuming default folds(5)\")\n",
        "  split =  5\n",
        " if val == 2:\n",
        "   for k in range(1,30):\n",
        "     main_call(val)\n",
        " if(val == 3):\n",
        "  main_call(310)\n",
        "  main_call(311)\n",
        "  main_call(312)\n",
        " elif(val == 8):\n",
        "  for i in range(1,8):\n",
        "    if(i == 3):\n",
        "      main_call(310)\n",
        "      main_call(311)\n",
        "      main_call(312)\n",
        "    else:main_call(i)\n",
        " else:main_call(val)\n",
        "#END#\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEITIadTo9rj"
      },
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = numpy.array([\n",
        "        [1.0,5.0],\n",
        "        [1.25,5.35],\n",
        "        [1.25,5.75],\n",
        "        [1.5,6.25],\n",
        "        [1.75,6.75],\n",
        "        [2.0,6.5],\n",
        "        [3.0,7.75],\n",
        "        [3.5,8.25],\n",
        "        [3.75,8.75],\n",
        "        [3.95,9.1],\n",
        "        [4.0,8.5],\n",
        "        [2.5,7.25],\n",
        "        [2.25,7.75],\n",
        "        [2.0,6.5],\n",
        "        [2.75,8.25],\n",
        "        [4.5,8.9],\n",
        "        [9.0,5.0],\n",
        "        [8.75,5.85],\n",
        "        [9.0,6.25],\n",
        "        [8.0,7.0],\n",
        "        [8.5,6.25],\n",
        "        [8.5,6.75],\n",
        "        [8.25,7.65],\n",
        "        [7.0,8.25],\n",
        "        [6.0,8.75],\n",
        "        [5.5,8.25],\n",
        "        [5.25,8.75],\n",
        "        [4.9,8.75],\n",
        "        [5.0,8.5],\n",
        "        [7.5,7.75],\n",
        "        [7.75,8.25],\n",
        "        [6.75,8.0],\n",
        "        [6.25,8.25],\n",
        "        [4.5,8.9],\n",
        "        [5.0,1.0],\n",
        "        [1.25,4.65],\n",
        "        [1.25,4.25],\n",
        "        [1.5,3.75],\n",
        "        [1.75,3.25],\n",
        "        [2.0,3.5],\n",
        "        [3.0,2.25],\n",
        "        [3.5,1.75],\n",
        "        [3.75,8.75],\n",
        "        [3.95,0.9],\n",
        "        [4.0,1.5],\n",
        "        [2.5,2.75],\n",
        "        [2.25,2.25],\n",
        "        [2.0,3.5],\n",
        "        [2.75,1.75],\n",
        "        [4.5,1.1],\n",
        "        [5.0,9.0],\n",
        "        [8.75,5.15],\n",
        "        [8.0,2.25],\n",
        "        [8.25,3.0],\n",
        "        [8.5,4.75],\n",
        "        [8.5,4.25],\n",
        "        [8.25,3.35],\n",
        "        [7.0,1.75],\n",
        "        [8.0,3.5],\n",
        "        [6.0,1.25],\n",
        "        [5.5,1.75],\n",
        "        [5.25,1.25],\n",
        "        [4.9,1.25],\n",
        "        [5.0,1.5],\n",
        "        [7.5,2.25],\n",
        "        [7.75,2.75],\n",
        "        [6.75,2.0],\n",
        "        [6.25,1.75],\n",
        "        [4.5,1.1],\n",
        "        [3.0,4.5],\n",
        "        [7.0,4.5],\n",
        "        [5.0,3.0],\n",
        "        [4.0,3.35],\n",
        "        [6.0,3.35],\n",
        "        [4.25,3.25],\n",
        "        [5.75,3.25],\n",
        "        [3.5,3.75],\n",
        "        [6.5,3.75],\n",
        "        [3.25,4.0],\n",
        "        [6.75,4.0],\n",
        "        [3.75,3.55],\n",
        "        [6.25,3.55],\n",
        "        [4.75,3.05],\n",
        "        [5.25,3.05],\n",
        "        [4.5,3.15],\n",
        "        [5.5,3.15],\n",
        "        [4.0,6.5],\n",
        "        [4.0,6.75],\n",
        "        [4.0,6.25],\n",
        "        [3.75,6.5],\n",
        "        [4.25,6.5],\n",
        "        [4.25,6.75],\n",
        "        [3.75,6.25],\n",
        "        [6.0,6.5],\n",
        "        [6.0,6.75],\n",
        "        [6.0,6.25],\n",
        "        [5.75,6.75],\n",
        "        [5.75,6.25],\n",
        "        [6.25,6.75],\n",
        "        [6.25,6.25],\n",
        "        [9.5,9.5],\n",
        "        [2.5,9.5],\n",
        "        [1.0,8.0]])\n",
        "\n",
        "def MyDBSCAN(D, eps, MinPts):\n",
        "      \n",
        "    labels = [0]*len(D)\n",
        "    C = 0\n",
        "    for P in range(0, len(D)):\n",
        "        if not (labels[P] == 0):\n",
        "           continue\n",
        "        NeighborPts = regionQuery(D, P, eps)\n",
        "        if len(NeighborPts) < MinPts:\n",
        "            labels[P] = -1\n",
        "        else: \n",
        "           C += 1\n",
        "           labels[P] = C\n",
        "           growCluster(D, labels, P, C, eps, MinPts)\n",
        "    return labels\n",
        "\n",
        "\n",
        "def growCluster(D, labels, P, C, eps, MinPts):\n",
        "    \"\"\"\n",
        "    Grow a new cluster with label `C` from the seed point `P`.\n",
        "    \n",
        "    This function searches through the dataset to find all points that belong\n",
        "    to this new cluster. When this function returns, cluster `C` is complete.\n",
        "    \n",
        "    Parameters:\n",
        "      `D`      - The dataset (a list of vectors)\n",
        "      `labels` - List storing the cluster labels for all dataset points\n",
        "      `P`      - Index of the seed point for this new cluster\n",
        "      `C`      - The label for this new cluster.  \n",
        "      `eps`    - Threshold distance\n",
        "      `MinPts` - Minimum required number of neighbors\n",
        "    \"\"\"\n",
        "\n",
        "    # SearchQueue is a FIFO queue of points to evaluate. It will only ever \n",
        "    # contain points which belong to cluster C (and have already been labeled\n",
        "    # as such).\n",
        "    #\n",
        "    # The points are represented by their index values (not the actual vector).\n",
        "    #\n",
        "    # The FIFO queue behavior is accomplished by appending new points to the\n",
        "    # end of the list, and using a while-loop rather than a for-loop.\n",
        "    SearchQueue = [P]\n",
        "\n",
        "    # For each point in the queue:\n",
        "    #   1. Determine whether it is a branch or a leaf\n",
        "    #   2. For branch points, add their unclaimed neighbors to the search queue\n",
        "    i = 0\n",
        "    while i < len(SearchQueue):    \n",
        "        \n",
        "        # Get the next point from the queue.        \n",
        "        P = SearchQueue[i]\n",
        "\n",
        "        # Find all the neighbors of P\n",
        "        NeighborPts = regionQuery(D, P, eps)\n",
        "        \n",
        "        # If the number of neighbors is below the minimum, then this is a leaf\n",
        "        # point and we move to the next point in the queue.\n",
        "        if len(NeighborPts) < MinPts:\n",
        "            i += 1\n",
        "            continue\n",
        "        \n",
        "        # Otherwise, we have the minimum number of neighbors, and this is a \n",
        "        # branch point.\n",
        "            \n",
        "        # For each of the neighbors...\n",
        "        for Pn in NeighborPts:\n",
        "           \n",
        "            # If Pn was labelled NOISE during the seed search, then we\n",
        "            # know it's not a branch point (it doesn't have enough \n",
        "            # neighbors), so make it a leaf point of cluster C and move on.\n",
        "            if labels[Pn] == -1:\n",
        "               labels[Pn] = C\n",
        "            # Otherwise, if Pn isn't already claimed, claim it as part of\n",
        "            # C and add it to the search queue.   \n",
        "            elif labels[Pn] == 0:\n",
        "                # Add Pn to cluster C.\n",
        "                labels[Pn] = C\n",
        "                \n",
        "                # Add Pn to the SearchQueue.\n",
        "                SearchQueue.append(Pn)\n",
        "            \n",
        "        # Advance to the next point in the FIFO queue.\n",
        "        i += 1        \n",
        "    \n",
        "    # We've finished growing cluster C!\n",
        "\n",
        "\n",
        "def regionQuery(D, P, eps):\n",
        "    \"\"\"\n",
        "    Find all points in dataset `D` within distance `eps` of point `P`.\n",
        "    \n",
        "    This function calculates the distance between a point P and every other \n",
        "    point in the dataset, and then returns only those points which are within a\n",
        "    threshold distance `eps`.\n",
        "    \"\"\"\n",
        "    neighbors = []\n",
        "    \n",
        "    # For each point in the dataset...\n",
        "    for Pn in range(0, len(D)):\n",
        "        \n",
        "        # If the distance is below the threshold, add it to the neighbors list.\n",
        "        if numpy.linalg.norm(D[P] - D[Pn]) < eps:\n",
        "           neighbors.append(Pn)\n",
        "            \n",
        "    return neighbors\n",
        "\n",
        "data = MyDBSCAN(X,0.6,3)\n",
        "#print(\"SDS\",type(data))\n",
        "color = ['red', 'blue', 'green']\n",
        "for i in range(len(data),0):\n",
        "      x = []\n",
        "      y = []   \n",
        "      print(x.append(data[i]))\n",
        "      y.append(data[i-1])\n",
        "      plt.scatter(x, y, color=color[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}